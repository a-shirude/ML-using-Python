{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import datasets\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7445887445887446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "diabetes=pd.read_csv(r\"C:\\Users\\Sampriti_Chatterjee\\Desktop\\diabetes.csv\")\n",
    "#dataset=diabetes[:]\n",
    "diabetes.columns\n",
    "diabetes.values\n",
    "data=diabetes.values\n",
    "data=diabetes.iloc[:,0:8]\n",
    "diabetes\n",
    "pre=diabetes['Outcome']\n",
    "X=data.values\n",
    "Y=pre.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) # 70% training and 30% test\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7539473684210527"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "diabetes=pd.read_csv(r\"C:\\Users\\Sampriti_Chatterjee\\Desktop\\diabetes.csv\")\n",
    "#dataset=diabetes[:]\n",
    "diabetes.columns\n",
    "diabetes.values\n",
    "data=diabetes.values\n",
    "data=diabetes.iloc[:,0:8]\n",
    "diabetes\n",
    "pre=diabetes['Outcome']\n",
    "X=data.values\n",
    "Y=pre.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) # 70% training and 30% test\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "results = model_selection.cross_val_score(abc, X, Y, cv=kfold)\n",
    "results.mean()\n",
    "#Predict the response for test dataset\n",
    "#y_pred = model.predict(X_test)\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,  94., 168.,   0.,  88.,   0., 543.,   0.,   0.,\n",
       "         0.,   0., 846., 175.,   0., 230.,   0.,  83.,  96., 235.,   0.,\n",
       "         0.,   0., 146., 115.,   0., 140., 110.,   0.,   0., 245.,  54.,\n",
       "         0.,   0., 192.,   0.,   0.,   0., 207.,  70.,   0.,   0., 240.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  82.,  36.,  23., 300., 342.,\n",
       "         0., 304., 110.,   0., 142.,   0.,   0.,   0., 128.,   0.,   0.,\n",
       "         0.,   0.,  38., 100.,  90., 140.,   0., 270.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  71.,   0.,   0., 125.,   0.,  71.,\n",
       "       110.,   0.,   0., 176.,  48.,   0.,  64., 228.,   0.,  76.,  64.,\n",
       "       220.,   0.,   0.,   0.,  40.,   0., 152.,   0., 140.,  18.,  36.,\n",
       "       135., 495.,  37.,   0., 175.,   0.,   0.,   0.,   0.,  51., 100.,\n",
       "         0., 100.,   0.,   0.,  99., 135.,  94., 145.,   0., 168.,   0.,\n",
       "       225.,   0.,  49., 140.,  50.,  92.,   0., 325.,   0.,   0.,  63.,\n",
       "         0., 284.,   0.,   0., 119.,   0.,   0., 204.,   0., 155., 485.,\n",
       "         0.,   0.,  94., 135.,  53., 114.,   0., 105., 285.,   0.,   0.,\n",
       "       156.,   0.,   0.,   0.,  78.,   0., 130.,   0.,  48.,  55., 130.,\n",
       "         0., 130.,   0.,   0.,   0.,  92.,  23.,   0.,   0.,   0., 495.,\n",
       "        58., 114., 160.,   0.,  94.,   0.,   0.,   0., 210.,   0.,  48.,\n",
       "        99., 318.,   0.,   0.,   0.,  44., 190.,   0., 280.,   0.,  87.,\n",
       "         0.,   0.,   0.,   0., 130., 175., 271., 129., 120.,   0.,   0.,\n",
       "       478.,   0.,   0., 190.,  56.,  32.,   0.,   0., 744.,  53.,   0.,\n",
       "       370.,  37.,   0.,  45.,   0., 192.,   0.,   0.,   0.,   0.,  88.,\n",
       "         0., 176., 194.,   0.,   0., 680., 402.,   0.,   0.,   0.,  55.,\n",
       "         0., 258.,   0.,   0.,   0., 375., 150., 130.,   0.,   0.,   0.,\n",
       "         0.,  67.,   0.,   0.,   0.,   0.,   0.,  56.,   0.,  45.,   0.,\n",
       "        57.,   0., 116.,   0., 278.,   0., 122., 155.,   0.,   0., 135.,\n",
       "       545., 220.,  49.,  75.,  40.,  74., 182., 194.,   0., 120., 360.,\n",
       "       215., 184.,   0.,   0., 135.,  42.,   0.,   0., 105., 132., 148.,\n",
       "       180., 205.,   0., 148.,  96.,  85.,   0.,  94.,  64.,   0., 140.,\n",
       "         0., 231.,   0.,   0.,  29.,   0., 168., 156.,   0., 120.,  68.,\n",
       "         0.,  52.,   0.,   0.,  58., 255.,   0.,   0., 171.,   0., 105.,\n",
       "        73.,   0.,   0.,   0., 108.,  83.,   0.,  74.,   0.,   0.,   0.,\n",
       "         0.,  43.,   0.,   0., 167.,   0.,  54., 249., 325.,   0.,   0.,\n",
       "         0., 293.,  83.,   0.,   0.,  66., 140., 465.,  89.,  66.,  94.,\n",
       "       158., 325.,  84.,  75.,   0.,  72.,  82.,   0., 182.,  59., 110.,\n",
       "        50.,   0.,   0., 285.,  81., 196.,   0., 415.,  87.,   0., 275.,\n",
       "       115.,   0.,   0.,   0.,   0.,   0.,  88.,   0.,   0., 165.,   0.,\n",
       "         0.,   0., 579.,   0., 176., 310.,  61., 167., 474.,   0.,   0.,\n",
       "         0., 115., 170.,  76.,  78.,   0., 210., 277.,   0., 180., 145.,\n",
       "       180.,   0.,  85.,  60.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  50., 120.,   0.,   0.,  14.,  70.,  92.,  64.,  63.,  95.,\n",
       "         0., 210.,   0., 105.,   0.,   0.,  71., 237.,  60.,  56.,   0.,\n",
       "        49.,   0.,   0., 105.,  36., 100.,   0., 140.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 191., 110.,  75.,   0., 328.,   0.,  49., 125.,\n",
       "         0., 250., 480., 265.,   0.,   0.,  66.,   0.,   0., 122.,   0.,\n",
       "         0.,   0.,  76., 145., 193.,  71.,   0.,   0.,  79.,   0.,   0.,\n",
       "        90., 170.,  76.,   0.,   0., 210.,   0.,   0.,  86., 105., 165.,\n",
       "         0.,   0., 326.,  66., 130.,   0.,   0.,   0.,   0.,  82., 105.,\n",
       "       188.,   0., 106.,   0.,  65.,   0.,  56.,   0.,   0.,   0., 210.,\n",
       "       155., 215., 190.,   0.,  56.,  76., 225., 207., 166.,  67.,   0.,\n",
       "         0., 106.,   0.,  44., 115., 215.,   0.,   0.,   0.,   0.,   0.,\n",
       "       274.,  77.,  54.,   0.,  88.,  18., 126., 126., 165.,   0.,   0.,\n",
       "        44., 120., 330.,  63., 130.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 600.,   0.,   0.,   0., 156.,   0.,   0., 140.,   0., 115.,\n",
       "       230., 185.,   0.,  25.,   0., 120.,   0.,   0.,   0., 126.,   0.,\n",
       "         0., 293.,  41., 272., 182., 158., 194., 321.,   0., 144.,   0.,\n",
       "         0.,  15.,   0.,   0., 160.,   0.,   0., 115.,   0.,  54.,   0.,\n",
       "         0.,   0.,   0.,   0.,  90.,   0., 183.,   0.,   0.,   0.,  66.,\n",
       "        91.,  46., 105.,   0.,   0.,   0., 152., 440., 144., 159., 130.,\n",
       "         0., 100., 106.,  77.,   0., 135., 540.,  90., 200.,   0.,  70.,\n",
       "         0.,   0., 231., 130.,   0., 132.,   0.,   0., 190., 100., 168.,\n",
       "         0.,  49., 240.,   0.,   0.,   0.,   0.,   0., 265.,  45.,   0.,\n",
       "       105.,   0.,   0., 205.,   0.,   0., 180., 180.,   0.,   0.,  95.,\n",
       "       125.,   0., 480., 125.,   0., 155.,   0., 200.,   0.,   0.,   0.,\n",
       "       100.,   0.,   0., 335.,   0., 160., 387.,  22.,   0., 291.,   0.,\n",
       "       392., 185.,   0., 178.,   0.,   0., 200., 127., 105.,   0.,   0.,\n",
       "       180.,   0.,   0.,   0.,  79.,   0., 120., 165.,   0.,   0., 120.,\n",
       "         0., 160.,   0., 150.,  94., 116.,   0., 140., 105.,   0.,  57.,\n",
       "       200.,   0.,   0.,  74.,   0., 510.,   0., 110.,   0.,   0.,   0.,\n",
       "         0.,  16.,   0.,   0., 180.,   0., 112.,   0.,   0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = diabetes.data\n",
    "#y = diabetes.target\n",
    "data\n",
    "rd=data[:,0:9]\n",
    "rd\n",
    "pd=data[:,4]\n",
    "pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
